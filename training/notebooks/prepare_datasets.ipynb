{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import pathlib\n",
    "from typing import Any, Callable, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets import VisionDataset\n",
    "from torchvision.datasets.utils import verify_str_arg, check_integrity\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['angry', 0.9658],\n",
       " ['disgust', 0.9553],\n",
       " ['fear', 0.981],\n",
       " ['happy', 0.9477],\n",
       " ['neutral', 0.2342],\n",
       " ['sad', 0.9788],\n",
       " ['surprise', 0.9369]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path(\"../data/ck_data\")\n",
    "all_count = len(list((data_path / \"train\").rglob(\"*.png\")))\n",
    "weights = []\n",
    "for e in list((data_path / \"train\").iterdir()):\n",
    "    weights.append([e.name, len(list(e.iterdir()))])\n",
    "\n",
    "def f(w):\n",
    "    new_w = list(w)\n",
    "    new_w[1] = round(1 - w[1] / all_count, 4)\n",
    "    return new_w\n",
    "\n",
    "weights = list(map(lambda x: f(x), weights))\n",
    "sorted(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../data/emotions_cv\")\n",
    "class_count = []\n",
    "for e in list((data_path / \"train\").iterdir()):\n",
    "    if e.name == \"contempt\":\n",
    "        continue\n",
    "    class_count.append(len(list(e.iterdir())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fear', 'neutral', 'angry', 'happy', 'disgust', 'sad', 'surprise'] [3326, 3979, 3353, 5909, 502, 3908, 2730]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 7 artists>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3024x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "names = [p.name for p in (data_path / \"train\").iterdir() if p.name != \"contempt\"]\n",
    "plt.figure(figsize=(42, 8))\n",
    "plt.subplot(131)\n",
    "print(names, class_count)\n",
    "plt.bar(names, class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/fer2013/full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5742, 2), (22967, 2))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shape, train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.to_csv(\"../data/fer2013/val.csv\", index=False)\n",
    "train.to_csv(\"../data/fer2013/train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FER2013(VisionDataset):\n",
    "    \"\"\"`FER2013\n",
    "    <https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge>`_ Dataset.\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where directory\n",
    "            ``root/fer2013`` exists.\n",
    "        split (string, optional): The dataset split, supports ``\"train\"`` (default), or ``\"test\"``.\n",
    "        transform (callable, optional): A function/transform that takes in an PIL image and returns a transformed\n",
    "            version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the target and transforms it.\n",
    "    \"\"\"\n",
    "\n",
    "    _RESOURCES = {\n",
    "        \"train\": (\"train.csv\", None),\n",
    "        \"test\": (\"test.csv\", None),\n",
    "        \"val\": (\"val.csv\", None),\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        split: str = \"train\",\n",
    "        transform: Optional[Callable] = None,\n",
    "        target_transform: Optional[Callable] = None,\n",
    "    ) -> None:\n",
    "        self._split = verify_str_arg(split, \"split\", self._RESOURCES.keys())\n",
    "        super().__init__(root, transform=transform, target_transform=target_transform)\n",
    "\n",
    "        base_folder = pathlib.Path(self.root) / \"fer2013\"\n",
    "        file_name, md5 = self._RESOURCES[self._split]\n",
    "        data_file = base_folder / file_name\n",
    "        if not check_integrity(str(data_file), md5=md5):\n",
    "            raise RuntimeError(\n",
    "                f\"{file_name} not found in {base_folder} or corrupted. \"\n",
    "                f\"You can download it from \"\n",
    "                f\"https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge\"\n",
    "            )\n",
    "\n",
    "        with open(data_file, \"r\", newline=\"\") as file:\n",
    "            self._samples = [\n",
    "                (\n",
    "                    torch.tensor(\n",
    "                        [int(idx) for idx in row[\"pixels\"].split()], dtype=torch.uint8\n",
    "                    ).reshape(48, 48),\n",
    "                    int(row[\"emotion\"]) if \"emotion\" in row else None,\n",
    "                )\n",
    "                for row in csv.DictReader(file)\n",
    "            ]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._samples)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[Any, Any]:\n",
    "        image_tensor, target = self._samples[idx]\n",
    "        image = Image.fromarray(image_tensor.numpy())\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"split={self._split}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FER2013(\"../data\", \"train\")\n",
    "valid_dataset = FER2013(\"../data\", \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"../data/fer2013/train\"\n",
    "val_dir = \"../data/fer2013/val\"\n",
    "emo_map = {\n",
    "    0: \"angry\",\n",
    "    1: \"disgust\", \n",
    "    2: \"fear\", \n",
    "    3: \"happy\", \n",
    "    4: \"sad\",\n",
    "    5: \"surprise\", \n",
    "    6: \"neutral\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22967/22967 [00:04<00:00, 4834.99it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, (image, target) in enumerate(tqdm(train_dataset)):\n",
    "    folder = emo_map[target]\n",
    "    os.makedirs(os.path.join(train_dir, folder), exist_ok=True)\n",
    "    image.save(os.path.join(train_dir, folder, str(i) + \".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5742/5742 [00:01<00:00, 4842.43it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, (image, target) in enumerate(tqdm(valid_dataset)):\n",
    "    folder = emo_map[target]\n",
    "    os.makedirs(os.path.join(val_dir, folder), exist_ok=True)\n",
    "    image.save(os.path.join(val_dir, folder, str(i) + \".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 225.99it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "ck_p = Path(\"../data/CK+48\")\n",
    "fer_p = Path(\"../data/fer2013/\")\n",
    "ck2fer = {\n",
    "    \"anger\": \"angry\",\n",
    "    \"contempt\": \"contempt\",\n",
    "    \"disgust\": \"disgust\",\n",
    "    \"fear\": \"fear\",\n",
    "    \"happy\": \"happy\",\n",
    "    \"sadness\": \"sad\",\n",
    "    \"surprise\": \"surprise\"\n",
    "}\n",
    "for e in tqdm(list(ck_p.iterdir())):\n",
    "    images_paths = list(e.iterdir())\n",
    "    train_imgs, val_imgs = train_test_split(images_paths, test_size=0.2, random_state=42)\n",
    "    (fer_p / \"train\" / ck2fer[e.name]).mkdir(exist_ok=True)\n",
    "    (fer_p / \"val\" / ck2fer[e.name]).mkdir(exist_ok=True)\n",
    "    for ti in train_imgs:\n",
    "        ti.rename(fer_p / \"train\" / ck2fer[e.name] / ti.name)\n",
    "    for vi in val_imgs:\n",
    "        vi.rename(fer_p / \"val\" / ck2fer[e.name] / vi.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['angry', 0.8832],\n",
       " ['contempt', 0.9985],\n",
       " ['disgust', 0.9825],\n",
       " ['fear', 0.8841],\n",
       " ['happy', 0.7942],\n",
       " ['neutral', 0.8614],\n",
       " ['sad', 0.8639],\n",
       " ['surprise', 0.9049]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = []\n",
    "for e in list((fer_p / \"train\").iterdir()):\n",
    "    weights.append([e.name, len(list(e.iterdir()))])\n",
    "\n",
    "def f(w):\n",
    "    new_w = list(w)\n",
    "    new_w[1] = round(1 - w[1] / len(df), 4)\n",
    "    return new_w\n",
    "\n",
    "weights = list(map(lambda x: f(x), weights))\n",
    "sorted(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "ck_p = Path(\"../data/CK+48\")\n",
    "final_p = Path(\"../data/ck_data\")\n",
    "\n",
    "for e in ck_p.iterdir():\n",
    "    images_paths = list(e.iterdir())\n",
    "    train_imgs, val_imgs = train_test_split(images_paths, test_size=0.2, random_state=42)\n",
    "    (final_p / \"train\" / e.name).mkdir(exist_ok=True)\n",
    "    (final_p / \"val\" / e.name).mkdir(exist_ok=True)\n",
    "    for ti in train_imgs:\n",
    "        ti.rename(final_p / \"train\" / e.name / ti.name)\n",
    "    for vi in val_imgs:\n",
    "        vi.rename(final_p / \"val\" / e.name / vi.name)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install \n",
    "- https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio\n",
    "- https://www.kaggle.com/datasets/ejlok1/surrey-audiovisual-expressed-emotion-savee\n",
    "- https://www.kaggle.com/datasets/ejlok1/toronto-emotional-speech-set-tess\n",
    "\n",
    "**RAVDESS**\n",
    "- Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    "- Vocal channel (01 = speech, 02 = song).\n",
    "- Emotion **(01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised)**.\n",
    "- Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
    "- Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
    "- Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "- Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
    "\n",
    "\n",
    "\n",
    "**SAVEE**\n",
    "- four native English male speakers (identified as DC, JE, JK, KL),\n",
    "- Emotion has been described psychologically in discrete categories: **anger, disgust, fear, happiness, sadness, surprise, neutral**. \n",
    "\n",
    "**TESS**\n",
    "- There are a set of 200 target words were spoken in the carrier phrase \"Say the word _' by two actresses (aged 26 and 64 years) and recordings were made of the set portraying each of seven emotions **(anger, disgust, fear, happiness, pleasant surprise, sadness, and neutral)**. There are 2800 data points (audio files) in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_DIR = Path(\"../data/emotions_audio/\")\n",
    "RAVDESS_DIR = Path(\"../data/emotions_audio_todo/RAVDESS\")\n",
    "SAVEE_DIR = Path(\"../data/emotions_audio_todo/SAVEE\")\n",
    "TESS_DIR = Path(\"../data/emotions_audio_todo/TESS\")\n",
    "\n",
    "ravdes_map = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"neutral\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fear\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprise\"\n",
    "}\n",
    "savee_map = {\n",
    "    \"a\": \"angry\",\n",
    "    \"d\": \"disgust\",\n",
    "    \"f\": \"fear\",\n",
    "    \"h\": \"happy\",\n",
    "    \"n\": \"neutral\",\n",
    "    \"sa\": \"sad\",\n",
    "    \"su\": \"surprise\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:00<00:00, 1345.38it/s]\n",
      "100%|██████████| 288/288 [00:00<00:00, 1339.64it/s]\n"
     ]
    }
   ],
   "source": [
    "def prepare_ravdess():\n",
    "    wavs = list(RAVDESS_DIR.rglob(\"*.wav\"))\n",
    "    train_wavs, val_wavs = train_test_split(wavs, test_size=0.2, random_state=42)\n",
    "    for stage, wavs in zip([\"train\", \"val\"], [train_wavs, val_wavs]):\n",
    "        for wav in tqdm(wavs):\n",
    "            code = wav.name.split(\"-\")[2]\n",
    "            e = ravdes_map[code]\n",
    "            (FINAL_DIR / stage / e).mkdir(exist_ok=True)\n",
    "            shutil.copy(wav, FINAL_DIR / stage / e / wav.name)\n",
    "prepare_ravdess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 384/384 [00:00<00:00, 3120.40it/s]\n",
      "100%|██████████| 96/96 [00:00<00:00, 3576.91it/s]\n"
     ]
    }
   ],
   "source": [
    "def prepare_savee():\n",
    "    wavs = list(SAVEE_DIR.rglob(\"*.wav\"))\n",
    "    train_wavs, val_wavs = train_test_split(wavs, test_size=0.2, random_state=42)\n",
    "    for stage, wavs in zip([\"train\", \"val\"], [train_wavs, val_wavs]):\n",
    "        for wav in tqdm(wavs):\n",
    "            code = wav.name[3]\n",
    "            if code == \"s\":\n",
    "                code += wav.name[4]\n",
    "            e = savee_map[code]\n",
    "            (FINAL_DIR / stage / e).mkdir(exist_ok=True)        \n",
    "            shutil.copy(wav, FINAL_DIR / stage / e / wav.name)\n",
    "prepare_savee()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2240/2240 [00:00<00:00, 5487.24it/s]\n",
      "100%|██████████| 560/560 [00:00<00:00, 6057.54it/s]\n"
     ]
    }
   ],
   "source": [
    "def prepare_tess():\n",
    "    wavs = list(TESS_DIR.rglob(\"*.wav\"))\n",
    "    train_wavs, val_wavs = train_test_split(wavs, test_size=0.2, random_state=42)\n",
    "    for stage, wavs in zip([\"train\", \"val\"], [train_wavs, val_wavs]):\n",
    "        for wav in tqdm(wavs):\n",
    "            e = wav.parts[-2].split(\"_\")[-1]\n",
    "            (FINAL_DIR / stage / e).mkdir(exist_ok=True)        \n",
    "            shutil.copy(wav, FINAL_DIR / stage / e / wav.name)\n",
    "prepare_tess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fear', 'neutral', 'angry', 'happy', 'disgust', 'sad', 'surprise'] [153, 226, 153, 156, 158, 153, 152]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 7 artists>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAFlCAYAAAATcxnyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVAUlEQVR4nO3dfbBtZX0f8O8PIYEoAZFbSpDmGuc2DtoR5dZgGjtYYkaNKbS+RGsUrA21hRjT5g+a2Mg0miFN2mYcW1OoDPiSGFJDoUpVJLE26SBeUHmRqEQuBQbh+q4hRoFf/9jr4uZyzr3nnnP2Pfc+fD4ze85az3p71nPW2ud7nrX22tXdAQA40B200RUAAFgPQg0AMAShBgAYglADAAxBqAEAhiDUAABDOHijK5AkRx99dG/evHmjqwEA7Oeuu+66L3X3pqWm7RehZvPmzdm2bdtGVwMA2M9V1e3LTXP5CQAYglADAAxBqAEAhiDUAABDEGoAgCEINQDAEIQaAGAIQg0AMAShBgAYglADAAxBqAEAhiDUAABDEGoAgCHsF9/SzcbYfO4HNroKC7X9/J/e6CoAsA/pqQEAhiDUAABDEGoAgCEINQDAEIQaAGAIQg0AMAShBgAYglADAAxBqAEAhiDUAABDEGoAgCEINQDAEIQaAGAIQg0AMAShBgAYglADAAxBqAEAhiDUAABDEGoAgCEINQDAEIQaAGAIQg0AMAShBgAYglADAAxBqAEAhiDUAABDEGoAgCEINQDAEIQaAGAIQg0AMAShBgAYwh5DTVUdX1V/UlWfqaqbq+oXp/Kjquqqqvr89PPxU3lV1Vur6taquqGqnrnonQAAWElPzf1J/nV3n5Dk5CRnV9UJSc5NcnV3b0ly9TSeJC9IsmV6nZXk7eteawCAXewx1HT33d19/TT8zSS3JDkuyWlJLplmuyTJ6dPwaUne2TPXJDmyqo5d74oDAMzbq3tqqmpzkmck+XiSY7r77mnSF5McMw0fl+SOucXunMoAABZmxaGmqh6X5H1J3tDd35if1t2dpPdmw1V1VlVtq6ptO3bs2JtFAQAeYUWhpqoOySzQvKe7/2gqvmfnZaXp571T+V1Jjp9b/IlT2cN09wXdvbW7t27atGm19QcASLKyTz9VknckuaW7/+PcpCuSnDENn5Hk8rnyV0+fgjo5ydfnLlMBACzEwSuY5+8leVWSG6vqU1PZryQ5P8mlVfXaJLcnedk07cokL0xya5L7krxmPSsMALCUPYaa7v7TJLXM5FOXmL+TnL3GegEA7BVPFAYAhiDUAABDEGoAgCEINQDAEIQaAGAIQg0AMAShBgAYglADAAxBqAEAhiDUAABDEGoAgCEINQDAEIQaAGAIQg0AMAShBgAYglADAAxBqAEAhiDUAABDEGoAgCEINQDAEIQaAGAIQg0AMAShBgAYglADAAxBqAEAhiDUAABDEGoAgCEINQDAEIQaAGAIQg0AMAShBgAYglADAAxBqAEAhiDUAABDEGoAgCEINQDAEIQaAGAIQg0AMAShBgAYglADAAxBqAEAhiDUAABDEGoAgCEINQDAEIQaAGAIQg0AMAShBgAYglADAAxBqAEAhiDUAABDEGoAgCEINQDAEIQaAGAIB290BQAOdJvP/cBGV2Ghtp//0xtdBVgRPTUAwBD01AArpkcC2J/pqQEAhiDUAABDEGoAgCEINQDAEPZ4o3BVXZTkRUnu7e6nTWXnJfn5JDum2X6lu6+cpv2bJK9N8kCS13f3hxZQ773i5kb2xujHS+KYYd8Y/VxyHu1/VvLpp4uTvC3JO3cp/0/d/dvzBVV1QpKXJ3lqkh9K8pGq+tvd/cA61BUADnijh71k4wLfHi8/dffHknxlhes7Lcl7u/uvu/u2JLcmedYa6gcAsCJruafmnKq6oaouqqrHT2XHJbljbp47pzIAgIVabah5e5InJzkxyd1J/sPerqCqzqqqbVW1bceOHXteAABgN1YVarr7nu5+oLsfTHJhvneJ6a4kx8/N+sSpbKl1XNDdW7t766ZNm1ZTDQCAh6wq1FTVsXOj/yjJTdPwFUleXlXfX1VPSrIlybVrqyIAwJ6t5CPdv5/klCRHV9WdSd6U5JSqOjFJJ9me5J8nSXffXFWXJvlMkvuTnO2TTwDAvrDHUNPdr1ii+B27mf8tSd6ylkoBAOwtTxQGAIYg1AAAQxBqAIAhCDUAwBCEGgBgCEINADAEoQYAGIJQAwAMQagBAIYg1AAAQxBqAIAhCDUAwBCEGgBgCEINADAEoQYAGIJQAwAMQagBAIYg1AAAQxBqAIAhCDUAwBCEGgBgCEINADAEoQYAGIJQAwAMQagBAIYg1AAAQxBqAIAhCDUAwBCEGgBgCEINADAEoQYAGIJQAwAMQagBAIYg1AAAQxBqAIAhCDUAwBCEGgBgCEINADAEoQYAGIJQAwAMQagBAIYg1AAAQxBqAIAhCDUAwBCEGgBgCEINADAEoQYAGIJQAwAMQagBAIYg1AAAQxBqAIAhCDUAwBCEGgBgCEINADAEoQYAGIJQAwAMQagBAIYg1AAAQxBqAIAhCDUAwBD2GGqq6qKqureqbporO6qqrqqqz08/Hz+VV1W9tapuraobquqZi6w8AMBOK+mpuTjJ83cpOzfJ1d29JcnV03iSvCDJlul1VpK3r081AQB2b4+hprs/luQruxSfluSSafiSJKfPlb+zZ65JcmRVHbtOdQUAWNZq76k5prvvnoa/mOSYafi4JHfMzXfnVPYIVXVWVW2rqm07duxYZTUAAGbWfKNwd3eSXsVyF3T31u7eumnTprVWAwB4lFttqLln52Wl6ee9U/ldSY6fm++JUxkAwEKtNtRckeSMafiMJJfPlb96+hTUyUm+PneZCgBgYQ7e0wxV9ftJTklydFXdmeRNSc5PcmlVvTbJ7UleNs1+ZZIXJrk1yX1JXrOAOgMAPMIeQ013v2KZSacuMW8nOXutlQIA2FueKAwADEGoAQCGINQAAEMQagCAIQg1AMAQhBoAYAhCDQAwBKEGABiCUAMADEGoAQCGINQAAEMQagCAIQg1AMAQhBoAYAhCDQAwBKEGABiCUAMADEGoAQCGINQAAEMQagCAIQg1AMAQhBoAYAhCDQAwBKEGABiCUAMADEGoAQCGINQAAEMQagCAIQg1AMAQhBoAYAhCDQAwBKEGABiCUAMADEGoAQCGINQAAEMQagCAIQg1AMAQhBoAYAhCDQAwBKEGABiCUAMADEGoAQCGINQAAEMQagCAIQg1AMAQhBoAYAhCDQAwBKEGABiCUAMADEGoAQCGINQAAEMQagCAIQg1AMAQhBoAYAhCDQAwBKEGABiCUAMADEGoAQCGINQAAEMQagCAIRy8loWranuSbyZ5IMn93b21qo5K8gdJNifZnuRl3f3VtVUTAGD31qOn5rndfWJ3b53Gz01ydXdvSXL1NA4AsFCLuPx0WpJLpuFLkpy+gG0AADzMWkNNJ/lwVV1XVWdNZcd0993T8BeTHLPUglV1VlVtq6ptO3bsWGM1AIBHuzXdU5PkJ7r7rqr6G0muqqo/n5/Y3V1VvdSC3X1BkguSZOvWrUvOAwCwUmvqqenuu6af9ya5LMmzktxTVccmyfTz3rVWEgBgT1YdaqrqsVV1+M7hJD+V5KYkVyQ5Y5rtjCSXr7WSAAB7spbLT8ckuayqdq7n97r7g1X1iSSXVtVrk9ye5GVrryYAwO6tOtR09xeSPH2J8i8nOXUtlQIA2FueKAwADEGoAQCGINQAAEMQagCAIQg1AMAQhBoAYAhCDQAwBKEGABiCUAMADEGoAQCGINQAAEMQagCAIQg1AMAQhBoAYAhCDQAwBKEGABiCUAMADEGoAQCGINQAAEMQagCAIQg1AMAQhBoAYAhCDQAwBKEGABiCUAMADEGoAQCGINQAAEMQagCAIQg1AMAQhBoAYAhCDQAwBKEGABiCUAMADEGoAQCGINQAAEMQagCAIQg1AMAQhBoAYAhCDQAwBKEGABiCUAMADEGoAQCGINQAAEMQagCAIQg1AMAQhBoAYAhCDQAwBKEGABiCUAMADEGoAQCGINQAAEMQagCAIQg1AMAQhBoAYAhCDQAwBKEGABiCUAMADEGoAQCGINQAAENYWKipqudX1Wer6taqOndR2wEASBYUaqrqMUn+c5IXJDkhySuq6oRFbAsAIFlcT82zktza3V/o7u8keW+S0xa0LQCAhYWa45LcMTd+51QGALAQ1d3rv9KqlyR5fnf/s2n8VUl+rLvPmZvnrCRnTaM/muSz616RjXN0ki9tdCX2Q9pledpmadpladpladplaaO1yw9396alJhy8oA3eleT4ufEnTmUP6e4LklywoO1vqKra1t1bN7oe+xvtsjxtszTtsjTtsjTtsrRHU7ss6vLTJ5JsqaonVdX3JXl5kisWtC0AgMX01HT3/VV1TpIPJXlMkou6++ZFbAsAIFnc5ad095VJrlzU+vdzQ15WWwfaZXnaZmnaZWnaZWnaZWmPmnZZyI3CAAD7mq9JAACGINTspap6fVXdUlXv2ei6HIiqanNV/ZNVLvut9a4Pizf9zm/a6Hrsj6rqvKr65ar6d1X1k/tge6c/Gp/u7hhcXlVdWVVHbnQ91otQs/f+ZZLndfcrV7uCqlrYvUwHgM1Jlgw1j/J2WZZ2GV93/1p3f2QfbOr0zL66hkGt9P2iZg7q7hd299cWXK19RqjZC1X1u0l+JMn/qqpfraqLquraqvpkVZ02zbO5qv5PVV0/vX58Kj9lKr8iyWc2cDdWZdqvW6rqwqq6uao+XFWHVdWTq+qDVXXdtH9Pmea/eHoI487ld/aynJ/kOVX1qar6pao6s6quqKo/TnJ1VT2uqq6e2u7Gne16IKmq/zG1x83TQyZTVd+qqrdU1aer6pqqOmYqf/I0fmNVvXlnO+16vEz/yb9hbhtvqapf3Ij9W6XHLHHs/HxVfWJqk/dV1Q8kDx07v1tV26rqc1X1oqn8zKq6vKo+WlWfr6o3TeUHVNtM7x2fq6o/zezBow87X6rq/Kr6TFXdUFW/PZXt7jh5/9y631ZVZy61num96B8m+a3p/Hvyvt3ztauqx1bVB6Zj5qaq+tmq+rXpOLqpqi6oqprmPWma79NJzt7gqu+1ZfZ1e1UdPU3fWlUfnYbPq6p3VdWfJXnXbs6VzTX7oul3JrkpyfE717nU9qZlTqqq/z29p32oqo7dmBZZoe722otXku2ZPZ3xN5L83FR2ZJLPJXlskh9IcuhUviXJtmn4lCR/meRJG70Pq9zvzUnuT3LiNH5pkp9LcnWSLVPZjyX542n44iQvmVv+W3Pt8P658jMz+xqNo6bxg5P84DR8dJJb870b2r+10e2wwrbauS+HZfbG8YQkneRnpvJ/n+SN0/D7k7xiGn7dLu300PEytf/10/BBSf4iyRM2el/XeOw8YW6eNyf5hblj54PTfm6Zjo9Dp2Pl7qk9d7bt1gOpbZKclOTG6X3iB6fj+5d3ni/Tvn127pg/cgXHyfz59LapnZZbz8POywPtleTFSS6cGz9i5/k2jb9r7jy7Icnfn4Z/K8lNG13/ddjX7UmOnsa3JvnoNHxekuuSHDaN7+5ceTDJyXPr3Z7Ze+1S2zskyf9Nsmkq+9nMHtGy4e2z3EtPzer9VJJzq+pTST6a2Zvu38rsILiwqm5M8od5eFfvtd192z6u53q6rbs/NQ1fl9kJ8uNJ/nBqh/+aZDUp/qru/so0XEl+o6puSPKRzL4z7Jg11HkjvH767/CazJ6svSXJdzL7w5R8r+2S5NmZHSdJ8nu7rOeh46W7tyf5clU9I7Nj75Pd/eVF7cACLHXsPG3qjboxySuTPHVu/ku7+8Hu/nySLyR5ylR+VXd/ubv/KskfJfmJA6xtnpPksu6+r7u/kUc+lPTrSb6d5B1V9Y+T3DeV7+44Wcpy6znQ3ZjkeVX1m1X1nO7+epLnVtXHp+PoHyR5as3uETmyuz82LfeuDarvWiy1r7tzxXRe7PSIc2Uqv727r1nh9n40ydOSXDW9x78xs28I2G+5Vr96leTF3f2w76yqqvOS3JPk6Zn91/jtucl/uc9qtxh/PTf8QGZh42vdfeIS896f6fJmVR2U5Pt2s975dnllkk1JTuru71bV9swC4wGhqk5J8pNJnt3d903dw4cm+W5P/+pk1nYrOfd2PV7+W2b/gf3NJBetQ3X3pV2PncMy6zU4vbs/PV0yOWVunl2fNdF7KD+Q2+YhPXtw6bOSnJpZz805mf2hXs5D59nk0FWu54DQ3Z+rqmcmeWGSN1fV1ZldWtra3XdM778HzPvF7iyzr/O/7133c9f3i+XOlSX/Di2zvcuS3Nzdz17lbuxzempW70NJfmHu+u0zpvIjktzd3Q8meVVmT1Qe1TeS3FZVL00euvHs6dO07Zl1tSez6/iHTMPfTHL4btZ5RJJ7p0Dz3CQ/vO61Xqwjknx1CjRPSXLyHua/JrNu32T2dSK7c1mS5yf5u5kdfwe6w5PcXVWHZBZm5720qg6a7vv4kXzvC2+fV1VHVdVhmd30+mdT+YHSNh9LcnrN7ik6PMnPzE+sqsclOaJnDy/9pcz+OUqWP05uT3JCVX3/1Dtx6h7Ws6fzb79WVT+U5L7ufndml5SeOU360rTPL0mSnt34+rWq2tk7seoPdmyUZfZ1e773vvriZRbdablzZW+299kkm6rq2dM8h1TVU3ezmg2np2b1fj3J7yS5YeqJuC3Ji5L8lyTvq6pXZ3ZfwIHeO7Mnr0zy9qp6Y2bB5b1JPp3kwiSXT5dh5tvhhiQPTOUXJ/nqLut7T5L/OXUlb0vy5wvfg/X1wSSvq6pbMntDWKqbd94bkry7qn51WnbZLubu/k5V/UlmvWMPrFN9N9K/TfLxJDumn/N/bP9fkmszu+/kdd397en/h2uTvC+zLvB3d/e25MBpm+6+vqr+ILNz5N7Mvidv3uGZnTeHZtYb/K+m8jdkieNk6p24NLN7Jm5L8sk9rOe9mV0ef31m99b8xfrv5UL9ncxudH4wyXeT/IvM/mDflOSLeXh7vibJRVXVST68j+u5Hpba18Myu6T465nd9rA7jzhXqmrz3mxvOq9ekuStVXVEZpnhd5Lst1975InCsIFq9omfv+rurqqXZ3Yz6JKf+JrC8/VJXjrdazKkqro4s5tf//su5WdmdpnhnCWWGbpt9uY4gd2dK6PTUwMb66Qkb5suY34tyT9daqaaPTDt/ZndZDrcH+21eJS0zYqOE3i001MDAAzBjcIAwBCEGgBgCEINADAEoQYAGIJQAwAMQagBAIbw/wFm1ZkymxUZ7wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 2304x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_path = Path(\"../data/emotions_audio_full\")\n",
    "class_count = []\n",
    "for e in list((data_path / \"train\").iterdir()):\n",
    "    class_count.append(len(list(e.iterdir())))\n",
    "plt.figure(figsize=(32, 6))\n",
    "plt.subplot(131)\n",
    "print(names, class_count)\n",
    "plt.bar(names, class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a855c4efa1bcffec0e0592d87e36d2dc47c870182d52bf8f025634bf46aad6f3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
